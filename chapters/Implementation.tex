% Implementation chapter

\chapter{Implementation}
% Begins theoream counter for this chapter.
\newtheorem{theorem}{Theorem}

\paragraph{  } The Wind programming language is run with an executable that is compiled from a C source code project. Wind is written in C to make the language highly performant and compile to a small executable size. One of Wind's main goals is for the language to run on embedded systems. However, another intention of Wind is to create a language which can also serve higher level abstractions (mapping, filtering, reducing), without extensive runtime and low level utilities.
\par Additionally, the implementation of Wind in C also ensures that no dynamic memory allocation is used. Only stack and data-segment (\codeword{static} declared in C/C++) memory are used during computation and runtime. The main buffers of Wind's data flow live in the data segment of the Wind executable. Many embedded systems have issues using heap allocation for memory, thus Wind tackles this issue efficiently.
\par The implementation of Wind is broken up into three main parts: \emph{translation}, \emph{execution} and \emph{computation}. Wind processes source code very differently from other languages as it does not have a traditional pipe line. The language does not use abstract syntax trees, nested-syntax, byte code,  or terminal grammar components. It is read as a series of commands and arguments, as explained in previous chapters. Therefore the phases between source code and resulting computation are quite unique. 
\par Translation is the component in which source code is matched against syntax patterns to transition the internal state of Wind, and loads arguments or data to appropriate buffers. Execution is the phase where the command found from translation is invoked with the current data on the load buffer. Lastly, computation is the component of Wind that manipulates the specific binary data formats to evaluate expressions and binary operations.
\par This chapter will detail the C-level implementation of Wind and the concepts behind the design.

\section{Translation}

\paragraph{  } In most programming languages, the source code is first tokenized, then arranged into an abstract syntax tree. This process is commonly referred to as parsing. Parsing traditionally involves looking through characters in source code by a grammar which is ordered by priority. This is useful for languages with a nested structure. Such as functional languages normally require parsing many different elements, such as function parameters, function bodies, variables, names and more. All of which only occur under certain parent elements.
\par Wind has no nested structure or syntax. It is a truly \emph{linear} language. This means instead of being concerned with the state of the syntactic structure, we are only concerned with the source code itself. For checking a direct \emph{match} for a sequence of characters within an input string, naive comparison or a form of regular expression is used. In Wind however, both of these approaches would be far too slow.
\par Naive matching of a collection of substrings against a target string has a high complexity. Regular expressions can indeed be fast, yet normally require heavy duty utilities. Regular expressions are usually compiled as non-deterministic state machines prior to being able to match or search strings. This is tricky to due in a small scale environment. More so, the syntactic elements of Wind are not overly complex. The true power of regex is revealed in the matching and searching of more intricate structures.
\par Wind uses a technique called \emph{static jump prefixing}, which uses nested jump tables to match prefixes of strings. These jump tables are created when the C-compiler detects a switch statement with 5 or more cases. Most modern C-compilers, including gcc, support this. Nested jump tables allow a syntactic element in source code to be translated to an instruction in $O(N_c)$, where $N_c$ is the number of characters in the element of the source code. The \emph{static} word in the title refers to the jump tables being formed at compile time, meaning they cannot be made or changed during the runtime of the executable. Dynamic jump tables are possible to implement, but would require the tedious task of compiling and running assembly code on the fly. Either way, the algorithm will work the same. First, let's look at the logic behind translating a single syntactic element using jump prefixing.

\begin{theorem}[Singular Jump Prefixing]
Let $s$ be a string composed of $n$ characters. Let $e$ be a syntactic element of $k$ characters. Let $T_k$ be table of $k$ positions. If a character corresponds to some non-negative integer $i$, for any position $k$ in $T_k$, it is located at some offset $i$ from the beginning of the table. 
\end{theorem}